{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifiers are a type of ensemble learning model that combines multiple smaller models into a more robust and accurate model. Random forest models use a number of weak learner algorithms (decision trees) and combine their output to make a final classification (or regression) decision. Structurally speaking, random forest models are very similar to their neural network counterparts. Random forest models have been a staple in machine learning algorithms for many years due to their robustness and scalability. Both output and feature selection of random forest models are easy to interpret, and they can easily handle outliers and nonlinear data.\n",
    "\n",
    "Take a moment to consider a few different reasons to the following question:\n",
    "\n",
    "If random forest models are fairly robust and clear, why would you want to replace them with a neural network?\n",
    "\n",
    "The answer depends on the type and complexity of the entire dataset. First and foremost, random forest models will only handle tabular data, so data such as images or natural language data cannot be used in a random forest without heavy modifications to the data. Neural networks can handle all sorts of data types and structures in raw format or with general transformations (such as converting categorical data).\n",
    "\n",
    "In addition, each model handles input data differently. Random forest models are dependent on each weak learner being trained on a subset of the input data. Once each weak learner is trained, the random forest model predicts the classification based on a consensus of the weak learners. In contrast, deep learning models evaluate input data within a single neuron, as well as across multiple neurons and layers.\n",
    "\n",
    "As a result, the deep learning model might be able to identify variability in a dataset that a random forest model could miss. However, a random forest model with a sufficient number of estimators and tree depth should be able to perform at a similar capacity to most deep learning models.\n",
    "\n",
    "To compare the implementation and performance of a random forest model versus a deep learning model, we’ll train and evaluate both models on the same data. This time, we’ll use a dataset that has been adapted from bank loan data (Links to an external site.) with more than 36,000 rows and 16 feature columns. From this dataset, we want to build a classifier that can predict whether or not a loan will or will not be paid provided their current loan status and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\otrin\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>Current_Loan_Amount</th>\n",
       "      <th>Term</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Years_in_current_job</th>\n",
       "      <th>Home_Ownership</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Monthly_Debt</th>\n",
       "      <th>Years_of_Credit_History</th>\n",
       "      <th>Months_since_last_delinquent</th>\n",
       "      <th>Number_of_Open_Accounts</th>\n",
       "      <th>Number_of_Credit_Problems</th>\n",
       "      <th>Current_Credit_Balance</th>\n",
       "      <th>Maximum_Open_Credit</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Tax_Liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fully_Paid</td>\n",
       "      <td>99999999</td>\n",
       "      <td>Short_Term</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2231892.0</td>\n",
       "      <td>8_years</td>\n",
       "      <td>Own_Home</td>\n",
       "      <td>Debt_Consolidation</td>\n",
       "      <td>29200.53</td>\n",
       "      <td>14.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>297996</td>\n",
       "      <td>750090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully_Paid</td>\n",
       "      <td>217646</td>\n",
       "      <td>Short_Term</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1184194.0</td>\n",
       "      <td>&lt;_1_year</td>\n",
       "      <td>Home_Mortgage</td>\n",
       "      <td>Debt_Consolidation</td>\n",
       "      <td>10855.08</td>\n",
       "      <td>19.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>122170</td>\n",
       "      <td>272052.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fully_Paid</td>\n",
       "      <td>548746</td>\n",
       "      <td>Short_Term</td>\n",
       "      <td>678.0</td>\n",
       "      <td>2559110.0</td>\n",
       "      <td>2_years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt_Consolidation</td>\n",
       "      <td>18660.28</td>\n",
       "      <td>22.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>437171</td>\n",
       "      <td>555038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fully_Paid</td>\n",
       "      <td>99999999</td>\n",
       "      <td>Short_Term</td>\n",
       "      <td>728.0</td>\n",
       "      <td>714628.0</td>\n",
       "      <td>3_years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt_Consolidation</td>\n",
       "      <td>11851.06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>203965</td>\n",
       "      <td>289784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fully_Paid</td>\n",
       "      <td>99999999</td>\n",
       "      <td>Short_Term</td>\n",
       "      <td>740.0</td>\n",
       "      <td>776188.0</td>\n",
       "      <td>&lt;_1_year</td>\n",
       "      <td>Own_Home</td>\n",
       "      <td>Debt_Consolidation</td>\n",
       "      <td>11578.22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>134083</td>\n",
       "      <td>220220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Loan_Status  Current_Loan_Amount        Term  Credit_Score  Annual_Income  \\\n",
       "0  Fully_Paid             99999999  Short_Term         741.0      2231892.0   \n",
       "1  Fully_Paid               217646  Short_Term         730.0      1184194.0   \n",
       "2  Fully_Paid               548746  Short_Term         678.0      2559110.0   \n",
       "3  Fully_Paid             99999999  Short_Term         728.0       714628.0   \n",
       "4  Fully_Paid             99999999  Short_Term         740.0       776188.0   \n",
       "\n",
       "  Years_in_current_job Home_Ownership             Purpose  Monthly_Debt  \\\n",
       "0              8_years       Own_Home  Debt_Consolidation      29200.53   \n",
       "1             <_1_year  Home_Mortgage  Debt_Consolidation      10855.08   \n",
       "2              2_years           Rent  Debt_Consolidation      18660.28   \n",
       "3              3_years           Rent  Debt_Consolidation      11851.06   \n",
       "4             <_1_year       Own_Home  Debt_Consolidation      11578.22   \n",
       "\n",
       "   Years_of_Credit_History  Months_since_last_delinquent  \\\n",
       "0                     14.9                          29.0   \n",
       "1                     19.6                          10.0   \n",
       "2                     22.6                          33.0   \n",
       "3                     16.0                          76.0   \n",
       "4                      8.5                          25.0   \n",
       "\n",
       "   Number_of_Open_Accounts  Number_of_Credit_Problems  Current_Credit_Balance  \\\n",
       "0                       18                          1                  297996   \n",
       "1                       13                          1                  122170   \n",
       "2                        4                          0                  437171   \n",
       "3                       16                          0                  203965   \n",
       "4                        6                          0                  134083   \n",
       "\n",
       "   Maximum_Open_Credit  Bankruptcies  Tax_Liens  \n",
       "0             750090.0           0.0        0.0  \n",
       "1             272052.0           1.0        0.0  \n",
       "2             555038.0           0.0        0.0  \n",
       "3             289784.0           0.0        0.0  \n",
       "4             220220.0           0.0        0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "loans_df = pd.read_csv('loan_status.csv')\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both Scikit-Learn’s RandomForestClassifier class and TensorFlow’s Sequential class require preprocessing, we can perform our preprocessing steps on all of the data—no need to keep track of separate scaled and unscaled data. For our first preprocessing workflow, let’s encode our categorical variables using Scikit-Learn’s OneHotEncoder class.\n",
    "\n",
    "First, we must make sure that none of our categorical variables require bucketing. To check this, let’s get the column names of categorical variables and check their number of unique values. Add and run the following code to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_Status              2\n",
       "Term                     2\n",
       "Years_in_current_job    11\n",
       "Home_Ownership           4\n",
       "Purpose                  7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "loans_cat = loans_df.dtypes[loans_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "loans_df[loans_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of unique values in our categorical variable, the “Years_in_current_job” column does have 11 unique values. Therefore, we should check the number of data points for each unique value to find out if any categorical variables can be bucketed together. Again, add and run the following code to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10+_years    13149\n",
       "2_years       3225\n",
       "3_years       2997\n",
       "<_1_year      2699\n",
       "5_years       2487\n",
       "4_years       2286\n",
       "1_year        2247\n",
       "6_years       2109\n",
       "7_years       2082\n",
       "8_years       1675\n",
       "9_years       1467\n",
       "Name: Years_in_current_job, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique value counts to see if binning is required\n",
    "loans_df.Years_in_current_job.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of data points for each unique value, all of the categorical values have a substantial number of data points. In this case, we have reason to leave the “Years_in_current_job” column alone because we don’t want to bucket common values together and cause confusion in the model.\n",
    "\n",
    "Since all of the categorical variables are ready for encoding, we can add and run the following code to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_Status_Fully_Paid</th>\n",
       "      <th>Loan_Status_Not_Paid</th>\n",
       "      <th>Term_Long_Term</th>\n",
       "      <th>Term_Short_Term</th>\n",
       "      <th>Years_in_current_job_10+_years</th>\n",
       "      <th>Years_in_current_job_1_year</th>\n",
       "      <th>Years_in_current_job_2_years</th>\n",
       "      <th>Years_in_current_job_3_years</th>\n",
       "      <th>Years_in_current_job_4_years</th>\n",
       "      <th>Years_in_current_job_5_years</th>\n",
       "      <th>...</th>\n",
       "      <th>Home_Ownership_Home_Mortgage</th>\n",
       "      <th>Home_Ownership_Own_Home</th>\n",
       "      <th>Home_Ownership_Rent</th>\n",
       "      <th>Purpose_Business_Loan</th>\n",
       "      <th>Purpose_Buy_House</th>\n",
       "      <th>Purpose_Buy_a_Car</th>\n",
       "      <th>Purpose_Debt_Consolidation</th>\n",
       "      <th>Purpose_Home_Improvements</th>\n",
       "      <th>Purpose_Medical_Bills</th>\n",
       "      <th>Purpose_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loan_Status_Fully_Paid  Loan_Status_Not_Paid  Term_Long_Term  \\\n",
       "0                     1.0                   0.0             0.0   \n",
       "1                     1.0                   0.0             0.0   \n",
       "2                     1.0                   0.0             0.0   \n",
       "3                     1.0                   0.0             0.0   \n",
       "4                     1.0                   0.0             0.0   \n",
       "\n",
       "   Term_Short_Term  Years_in_current_job_10+_years  \\\n",
       "0              1.0                             0.0   \n",
       "1              1.0                             0.0   \n",
       "2              1.0                             0.0   \n",
       "3              1.0                             0.0   \n",
       "4              1.0                             0.0   \n",
       "\n",
       "   Years_in_current_job_1_year  Years_in_current_job_2_years  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           1.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   Years_in_current_job_3_years  Years_in_current_job_4_years  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           1.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   Years_in_current_job_5_years  ...  Home_Ownership_Home_Mortgage  \\\n",
       "0                           0.0  ...                           0.0   \n",
       "1                           0.0  ...                           1.0   \n",
       "2                           0.0  ...                           0.0   \n",
       "3                           0.0  ...                           0.0   \n",
       "4                           0.0  ...                           0.0   \n",
       "\n",
       "   Home_Ownership_Own_Home  Home_Ownership_Rent  Purpose_Business_Loan  \\\n",
       "0                      1.0                  0.0                    0.0   \n",
       "1                      0.0                  0.0                    0.0   \n",
       "2                      0.0                  1.0                    0.0   \n",
       "3                      0.0                  1.0                    0.0   \n",
       "4                      1.0                  0.0                    0.0   \n",
       "\n",
       "   Purpose_Buy_House  Purpose_Buy_a_Car  Purpose_Debt_Consolidation  \\\n",
       "0                0.0                0.0                         1.0   \n",
       "1                0.0                0.0                         1.0   \n",
       "2                0.0                0.0                         1.0   \n",
       "3                0.0                0.0                         1.0   \n",
       "4                0.0                0.0                         1.0   \n",
       "\n",
       "   Purpose_Home_Improvements  Purpose_Medical_Bills  Purpose_Other  \n",
       "0                        0.0                    0.0            0.0  \n",
       "1                        0.0                    0.0            0.0  \n",
       "2                        0.0                    0.0            0.0  \n",
       "3                        0.0                    0.0            0.0  \n",
       "4                        0.0                    0.0            0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(loans_df[loans_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(loans_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our categorical variables have been encoded, we need to merge them back into our original data frame and remove the unencoded columns. To do this, add and run the following code in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current_Loan_Amount</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Debt</th>\n",
       "      <th>Years_of_Credit_History</th>\n",
       "      <th>Months_since_last_delinquent</th>\n",
       "      <th>Number_of_Open_Accounts</th>\n",
       "      <th>Number_of_Credit_Problems</th>\n",
       "      <th>Current_Credit_Balance</th>\n",
       "      <th>Maximum_Open_Credit</th>\n",
       "      <th>...</th>\n",
       "      <th>Home_Ownership_Home_Mortgage</th>\n",
       "      <th>Home_Ownership_Own_Home</th>\n",
       "      <th>Home_Ownership_Rent</th>\n",
       "      <th>Purpose_Business_Loan</th>\n",
       "      <th>Purpose_Buy_House</th>\n",
       "      <th>Purpose_Buy_a_Car</th>\n",
       "      <th>Purpose_Debt_Consolidation</th>\n",
       "      <th>Purpose_Home_Improvements</th>\n",
       "      <th>Purpose_Medical_Bills</th>\n",
       "      <th>Purpose_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999999</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2231892.0</td>\n",
       "      <td>29200.53</td>\n",
       "      <td>14.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>297996</td>\n",
       "      <td>750090.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217646</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1184194.0</td>\n",
       "      <td>10855.08</td>\n",
       "      <td>19.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>122170</td>\n",
       "      <td>272052.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548746</td>\n",
       "      <td>678.0</td>\n",
       "      <td>2559110.0</td>\n",
       "      <td>18660.28</td>\n",
       "      <td>22.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>437171</td>\n",
       "      <td>555038.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99999999</td>\n",
       "      <td>728.0</td>\n",
       "      <td>714628.0</td>\n",
       "      <td>11851.06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>203965</td>\n",
       "      <td>289784.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99999999</td>\n",
       "      <td>740.0</td>\n",
       "      <td>776188.0</td>\n",
       "      <td>11578.22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>134083</td>\n",
       "      <td>220220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current_Loan_Amount  Credit_Score  Annual_Income  Monthly_Debt  \\\n",
       "0             99999999         741.0      2231892.0      29200.53   \n",
       "1               217646         730.0      1184194.0      10855.08   \n",
       "2               548746         678.0      2559110.0      18660.28   \n",
       "3             99999999         728.0       714628.0      11851.06   \n",
       "4             99999999         740.0       776188.0      11578.22   \n",
       "\n",
       "   Years_of_Credit_History  Months_since_last_delinquent  \\\n",
       "0                     14.9                          29.0   \n",
       "1                     19.6                          10.0   \n",
       "2                     22.6                          33.0   \n",
       "3                     16.0                          76.0   \n",
       "4                      8.5                          25.0   \n",
       "\n",
       "   Number_of_Open_Accounts  Number_of_Credit_Problems  Current_Credit_Balance  \\\n",
       "0                       18                          1                  297996   \n",
       "1                       13                          1                  122170   \n",
       "2                        4                          0                  437171   \n",
       "3                       16                          0                  203965   \n",
       "4                        6                          0                  134083   \n",
       "\n",
       "   Maximum_Open_Credit  ...  Home_Ownership_Home_Mortgage  \\\n",
       "0             750090.0  ...                           0.0   \n",
       "1             272052.0  ...                           1.0   \n",
       "2             555038.0  ...                           0.0   \n",
       "3             289784.0  ...                           0.0   \n",
       "4             220220.0  ...                           0.0   \n",
       "\n",
       "   Home_Ownership_Own_Home  Home_Ownership_Rent  Purpose_Business_Loan  \\\n",
       "0                      1.0                  0.0                    0.0   \n",
       "1                      0.0                  0.0                    0.0   \n",
       "2                      0.0                  1.0                    0.0   \n",
       "3                      0.0                  1.0                    0.0   \n",
       "4                      1.0                  0.0                    0.0   \n",
       "\n",
       "   Purpose_Buy_House  Purpose_Buy_a_Car  Purpose_Debt_Consolidation  \\\n",
       "0                0.0                0.0                         1.0   \n",
       "1                0.0                0.0                         1.0   \n",
       "2                0.0                0.0                         1.0   \n",
       "3                0.0                0.0                         1.0   \n",
       "4                0.0                0.0                         1.0   \n",
       "\n",
       "   Purpose_Home_Improvements  Purpose_Medical_Bills  Purpose_Other  \n",
       "0                        0.0                    0.0            0.0  \n",
       "1                        0.0                    0.0            0.0  \n",
       "2                        0.0                    0.0            0.0  \n",
       "3                        0.0                    0.0            0.0  \n",
       "4                        0.0                    0.0            0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "loans_df = loans_df.merge(encode_df,left_index=True, right_index=True)\n",
    "loans_df = loans_df.drop(loans_cat,1)\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to standardize our numerical variables using Scikit-Learn’s StandardScaler class. Again, we must split our data into the training and testing sets prior to standardization to not incorporate the testing values into the scale. To perform the training/test split and standardize our numerical variables, add and run the following code in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove loan status target from features data\n",
    "y = loans_df.Loan_Status_Fully_Paid\n",
    "X = loans_df.drop(columns=[\"Loan_Status_Fully_Paid\",\"Loan_Status_Not_Paid\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing variables in both the training and testing data, our dataset is ready for both models. First, we’ll train and evaluate our random forest classifier.\n",
    "\n",
    "Random forest models can be built using Scikit-learn’s RandomForestClassifier class in the ensemble module.\n",
    "\n",
    "For our purposes, we’ll use a random forest classifier with the n_estimators parameter set to 128. Typically, 128 estimators is the largest number of estimators we would want to use in a model. To create our random forest classifier model and test the performance, add and run the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.849\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to build, compile, and evaluate our deep learning model. Again, we’ll use our typical binary classifier parameters:\n",
    "\n",
    "Our first hidden layer will have an input_dim equal to 38, 24 neuron units, and will use the relu activation function.\n",
    "Our second hidden layer will have 12 neuron units and also will use the relu activation function.\n",
    "The loss function should be binary_crossentropy, using the adam optimizer.\n",
    "Our model should provide the additional accuracy scoring metric and train over a maximum of 50 epochs.\n",
    "\n",
    "To build and evaluate our deep learning model, we must add and run the following code to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  24\n",
    "hidden_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if we compare both model’s predictive accuracy, their output is very similar. Both the random forest and deep learning models were able to predict correctly whether or not a loan will be repaid over 80% of the time. Although their predictive performance was comparable, their implementation and training times were not—the random forest classifier was able to train on the large dataset and predict values in seconds, while the deep learning model required a couple minutes to train on the tens of thousands of data points. In other words, the random forest model is able to achieve comparable predictive accuracy on large tabular data with less code and faster performance. The ultimate decision of whether to use a random forest versus a neural network comes down to preference. However, if your dataset is tabular, random forest is a great place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints Are Not Just for Video Games\n",
    "\n",
    "Neural networks, especially complex neural networks, are resource-hungary algorithms. When it comes to training neural networks on medium to large datasets, the amount of computation time to adequately train a model can take hours (or even days!) With simple modelling problems, like the ones covered in this module, training a model in the same notebook as an analysis is no problem. However, with more formal applications of neural network and deep learning models, data scientists cannot afford the time or resources to build and train a model each time they analyze data. In these cases, a trained model must be stored and accessed outside of the training environment.\n",
    "\n",
    "With TensorFlow, we have the ability to save and load neural network models at any stage, including partially trained models. When building a TensorFlow model, if we use Keras’ ModelCheckpoint method, we can save the model weights after it tests a set number of data points. Then, at any point, we can reload the checkpoint weights and resume model training. Saving checkpoints while training has a number of benefits:\n",
    "\n",
    "We can short-circuit our training loop at any time (stop the function by pressing CTRL+C, or by pressing the stop button at the top of the notebook). This can be helpful if the model is showing signs of overfitting.\n",
    "The model is protected from computer problems (power failure, computer crash, etc.). Worst-case scenario: We would lose five epochs’ worth of optimization.\n",
    "We can restore previous model weight coefficients to try and revert overfitting.\n",
    "Let’s practice generating checkpoint files and loading model weights from different epochs. To make things simple, we’ll implement checkpoints to our previous deep learning example notebook. To start, we’ll open our “DeepLearning_Tabular” (or whatever similar name you may have used) notebook and rerun all of the code in the notebook for the following steps:\n",
    "\n",
    "1. Import dependencies.\n",
    "2. Import the input dataset.\n",
    "3. Generate categorical variable list.\n",
    "4. Create a OneHotEncoder instance.\n",
    "5. Fit and transform the OneHotEncoder.\n",
    "6. Add the encoded variable names to the DataFrame.\n",
    "7. Merge one-hot encoded features and drop the originals.\n",
    "8. Split the preprocessed data into features and target arrays.\n",
    "9. Split the preprocessed data into training and testing dataset.\n",
    "10. Create a StandardScaler instance.\n",
    "11. Fit the StandardScaler.\n",
    "12. Scale the data.\n",
    "13. Define the model.\n",
    "14. Add first and second hidden layers.\n",
    "15 Add the output layer.\n",
    "16. Check the structure of the model.\n",
    "\n",
    "__REWIND__\n",
    "\n",
    "You have coded all of these steps within this module. If you get stuck, or something is not working, try going back to earlier sections and recopy the code blocks.\n",
    "Now that we have our training data ready, we can implement checkpoints to our deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
